{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m patch_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m)  \u001b[38;5;66;03m# Maximum size of the patch to extract\u001b[39;00m\n\u001b[1;32m     77\u001b[0m max_perturbation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m  \u001b[38;5;66;03m# Maximum perturbation range [-max_perturbation, max_perturbation]\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m \u001b[43mgenerate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_perturbation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_warped\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# image_folder = \"../Data/Train\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# output_folder = \"../Data/Train_generated_data\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# generate_data(image_folder, output_folder, patch_size, max_perturbation, num_warped=5)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 31\u001b[0m, in \u001b[0;36mgenerate_data\u001b[0;34m(image_folder, output_folder, patch_size, max_perturbation, num_warped)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Read the image\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_folder, filename)\n\u001b[0;32m---> 31\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Function to save H4Pt to a CSV file\n",
    "def save_h4pt(output_folder, output_filename, h4pt, index):\n",
    "    h4pt_file = os.path.join(output_folder, \"homography_gt.csv\")\n",
    "    # Append mode for writing the H4Pt values to the CSV file\n",
    "    with open(h4pt_file, 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow([f\"{output_filename}_warped_{index}.jpg\"] + list(h4pt.flatten()))\n",
    "\n",
    "# Function to generate synthetic pairs of images with known homography and H4Pt labels\n",
    "def generate_data(image_folder, output_folder, patch_size, max_perturbation, num_warped=2):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Initialize CSV file (overwrite if exists)\n",
    "    h4pt_file = os.path.join(output_folder, \"homography_gt.csv\")\n",
    "    with open(h4pt_file, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['original_patch', 'warped_patch', 'x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'x4', 'y4'])\n",
    "\n",
    "    # Iterate through all images in the folder\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Read the image\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "\n",
    "            h, w = image.shape[:2]\n",
    "\n",
    "            # Iterate to create multiple warped pairs from each image\n",
    "            for i in range(num_warped):\n",
    "                # Random patch size within the specified range\n",
    "                patch_height = np.random.randint(patch_size[0]//2, patch_size[0])\n",
    "                patch_width = np.random.randint(patch_size[1]//2, patch_size[1])\n",
    "\n",
    "                # Randomly select the top-left corner of the patch\n",
    "                x = np.random.randint(0, w - patch_width)\n",
    "                y = np.random.randint(0, h - patch_height)\n",
    "                patch = image[y:y + patch_height, x:x + patch_width]\n",
    "                patch_corners = np.array([[x, y], [x + patch_width, y], [x, y + patch_height], [x + patch_width, y + patch_height]])\n",
    "\n",
    "                # Generate random perturbation within [-max_perturbation, max_perturbation]\n",
    "                perturbation = np.random.uniform(-max_perturbation, max_perturbation, size=(4, 2))\n",
    "                perturbed_corners = patch_corners + perturbation\n",
    "\n",
    "                # Calculate homography between original and perturbed corners\n",
    "                h_matrix, _ = cv2.findHomography(patch_corners, perturbed_corners)\n",
    "\n",
    "                # Calculate H4Pt labels\n",
    "                h4pt = perturbed_corners - patch_corners\n",
    "\n",
    "                # Warp the original image using the inverse of the homography\n",
    "                warped_image = cv2.warpPerspective(image, np.linalg.inv(h_matrix), (w, h))\n",
    "\n",
    "                # Extract corresponding patch from the warped image\n",
    "                warped_patch = warped_image[y:y + patch_height, x:x + patch_width]\n",
    "\n",
    "                # Save the original and warped patches as separate images\n",
    "                output_filename = os.path.splitext(filename)[0]\n",
    "                cv2.imwrite(os.path.join(output_folder, f\"{output_filename}_original_{i}.jpg\"), patch)\n",
    "                cv2.imwrite(os.path.join(output_folder, f\"{output_filename}_warped_{i}.jpg\"), warped_patch)\n",
    "\n",
    "                # Save the H4Pt values to the CSV file\n",
    "                save_h4pt(output_folder, output_filename, h4pt, i)\n",
    "\n",
    "# Example usage\n",
    "image_folder = \"../Data/Val\"\n",
    "output_folder = \"../Data/Val_generated_data\"\n",
    "patch_size = (100, 100)  # Maximum size of the patch to extract\n",
    "max_perturbation = 20  # Maximum perturbation range [-max_perturbation, max_perturbation]\n",
    "\n",
    "generate_data(image_folder, output_folder, patch_size, max_perturbation, num_warped=5)\n",
    "\n",
    "image_folder = \"../Data/Train\"\n",
    "output_folder = \"../Data/Train_generated_data\"\n",
    "generate_data(image_folder, output_folder, patch_size, max_perturbation, num_warped=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def save_h4pt(output_folder, output_filename, h4pt, index):\n",
    "    h4pt_file = os.path.join(output_folder, \"homography_gt.csv\")\n",
    "    with open(h4pt_file, 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow([f\"{output_filename}_warped_{index}.jpg\"] + list(h4pt.flatten()))\n",
    "\n",
    "def generate_data(image, patch_size=128, max_perturbation=24):\n",
    "    h, w = image.shape[:2]\n",
    "    x = np.random.randint(patch_size // 2, w - patch_size // 2)\n",
    "    y = np.random.randint(patch_size // 2, h - patch_size // 2)\n",
    "    \n",
    "    original_patch = image[y - patch_size // 2:y + patch_size // 2, x - patch_size // 2:x + patch_size // 2]\n",
    "    \n",
    "    corners = np.array([[x - patch_size // 2, y - patch_size // 2],\n",
    "                        [x + patch_size // 2, y - patch_size // 2],\n",
    "                        [x - patch_size // 2, y + patch_size // 2],\n",
    "                        [x + patch_size // 2, y + patch_size // 2]], dtype=np.float32)\n",
    "    \n",
    "    perturbation = np.random.uniform(-max_perturbation, max_perturbation, size=(4, 2)).astype(np.float32)\n",
    "    perturbed_corners = corners + perturbation\n",
    "\n",
    "    homography_ab = cv2.getPerspectiveTransform(corners, perturbed_corners)\n",
    "    warped_image = cv2.warpPerspective(image, np.linalg.inv(homography_ab), (w, h))\n",
    "\n",
    "    warped_patch = warped_image[y - patch_size // 2:y + patch_size // 2, x - patch_size // 2:x + patch_size // 2]\n",
    "    \n",
    "    return original_patch, warped_patch, perturbation, corners, homography_ab\n",
    "\n",
    "def generate_DataSet(image_folder, output_folder, patch_size=128, max_perturbation=24, num_warped=10):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    orig_output_dir = os.path.join(output_folder, 'Original')\n",
    "    warp_output_dir = os.path.join(output_folder, 'Warped')\n",
    "    labels_output_dir = output_folder\n",
    "\n",
    "    if not os.path.exists(orig_output_dir):\n",
    "        os.makedirs(orig_output_dir)\n",
    "    if not os.path.exists(warp_output_dir):\n",
    "        os.makedirs(warp_output_dir)\n",
    "    \n",
    "    perturbation_list = []\n",
    "    homography_list = []\n",
    "    corners_list = []\n",
    "    count = 0\n",
    "\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if image is None:\n",
    "                continue\n",
    "            \n",
    "            for i in range(num_warped):\n",
    "                original_patch, warped_patch, perturbation, corners, homography_ab = generate_data(image, patch_size, max_perturbation)\n",
    "                \n",
    "                cv2.imwrite(os.path.join(orig_output_dir, f\"{count}_{i}_original.jpg\"), original_patch)\n",
    "                cv2.imwrite(os.path.join(warp_output_dir, f\"{count}_{i}_warped.jpg\"), warped_patch)\n",
    "                \n",
    "                perturbation_list.append(perturbation)\n",
    "                homography_list.append(homography_ab)\n",
    "                corners_list.append(corners)\n",
    "                \n",
    "                count += 1\n",
    "\n",
    "    np.save(os.path.join(labels_output_dir, 'Perturbations.npy'), perturbation_list)\n",
    "    np.save(os.path.join(labels_output_dir, 'Homographies.npy'), homography_list)\n",
    "    np.save(os.path.join(labels_output_dir, 'Corners.npy'), corners_list)\n",
    "\n",
    "\n",
    "image_folder = \"../Data/Val\"\n",
    "output_folder = \"../Data/Val_generated_data\"\n",
    "generate_DataSet(image_folder, output_folder, patch_size=128, max_perturbation=24, num_warped=5)\n",
    "\n",
    "# image_folder = \"../Data/Train\"\n",
    "# output_folder = \"../Data/Train_generated_data\"\n",
    "# generate_DataSet(image_folder, output_folder, patch_size=128, max_perturbation=24, num_warped=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rbe549",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
